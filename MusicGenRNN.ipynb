{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGenRNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYsyNuSKIHnu"
      },
      "source": [
        "import sys\n",
        "import re \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import music21\n",
        "from glob import glob\n",
        "import IPython\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enhgpuyKIONI"
      },
      "source": [
        "\n",
        "def get_notes():\n",
        "    notes = []\n",
        "    for file in songs:\n",
        "        # converting .mid file to stream object\n",
        "        midi = converter.parse(file)\n",
        "        notes_to_parse = []\n",
        "        try:\n",
        "            # Given a single stream, partition into a part for each unique instrument\n",
        "            parts = instrument.partitionByInstrument(midi)\n",
        "        except:\n",
        "            pass\n",
        "        if parts: # if parts has instrument parts \n",
        "            notes_to_parse = parts.parts[0].recurse()\n",
        "        else:\n",
        "            notes_to_parse = midi.flat.notes\n",
        "    \n",
        "        for element in notes_to_parse: \n",
        "            if isinstance(element, note.Note):\n",
        "                # if element is a note, extract pitch\n",
        "                notes.append(str(element.pitch))\n",
        "            elif(isinstance(element, chord.Chord)):\n",
        "                # if element is a chord, append the normal form of the \n",
        "                # chord (a list of integers) to the list of notes. \n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "    \n",
        "    return notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xybXQt7MJRcd",
        "outputId": "2fa11b4d-45a6-46f3-dfac-fd2608c1c4b1"
      },
      "source": [
        "\n",
        "import pygame\n",
        "\n",
        "def play_music(music_file):\n",
        "    \"\"\"\n",
        "    stream music with mixer.music module in blocking manner\n",
        "    this will stream the sound from disk while playing\n",
        "    \"\"\"\n",
        "    clock = pygame.time.Clock()\n",
        "    try:\n",
        "        pygame.mixer.music.load(music_file)\n",
        "        print (\"Music file %s loaded!\" % music_file)\n",
        "    except pygame.error:\n",
        "        print (\"File %s not found! (%s)\" % (music_file, pygame.get_error()))\n",
        "        return\n",
        "    pygame.mixer.music.play()\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        # check if playback has finished\n",
        "        clock.tick(30)\n",
        "# pick a midi music file you have ...\n",
        "# (if not in working folder use full path)\n",
        "\n",
        "def play_midi(midi_file):\n",
        "    freq = 44100    # audio CD quality\n",
        "    bitsize = -16   # unsigned 16 bit\n",
        "    channels = 2    # 1 is mono, 2 is stereo\n",
        "    buffer = 1024    # number of samples\n",
        "    pygame.mixer.init(freq, bitsize, channels, buffer)\n",
        "\n",
        "    # optional volume 0 to 1.0\n",
        "    pygame.mixer.music.set_volume(0.8)\n",
        "    try:\n",
        "        play_music(midi_file)\n",
        "    except KeyboardInterrupt:\n",
        "        # if user hits Ctrl/C then exit\n",
        "        # (works only in console mode)\n",
        "        pygame.mixer.music.fadeout(1000)\n",
        "        pygame.mixer.music.stop()\n",
        "        raise SystemExit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 2.0.1 (SDL 2.0.14, Python 3.7.10)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO0SN5zHKju5"
      },
      "source": [
        "\n",
        "def prepare_sequences(notes, n_vocab): \n",
        "    sequence_length = 100\n",
        "\n",
        "    # Extract the unique pitches in the list of notes.\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i: i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "    \n",
        "    n_patterns = len(network_input)\n",
        "    \n",
        "    # reshape the input into a format comatible with LSTM layers \n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    \n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "    \n",
        "    # one hot encode the output vectors\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "    \n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAZQFKE3KpOI"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n",
        "def create_network(network_in, n_vocab): \n",
        "    \"\"\"Create the model architecture\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=network_in.shape[1:], return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "_mqgslpYLDgr",
        "outputId": "74e152e1-5628-47a3-8500-3943ce5731b8"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "def train(model, network_input, network_output, epochs): \n",
        "    \"\"\"\n",
        "    Train the neural network\n",
        "    \"\"\"\n",
        "    # Create checkpoint to save the best model weights.\n",
        "    filepath = 'weights.best.music3.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
        "    \n",
        "    model.fit(network_input, network_output, epochs=epochs, batch_size=32, callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-352d8d1548bc>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    filepath = 'C:\\Users\\goura\\Documents\\music-generation-using-rnn-master\\weights.best.music3.hdf5'\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UijYUG2wLFQ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "sPwsLrHaLG5i",
        "outputId": "e7d209fb-274b-405c-c059-1a6d57b1f89e"
      },
      "source": [
        "### Train the model \n",
        "train_network()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9d01840b2f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-b2aa50d73127>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Notes processed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-57b2cd690cd4>\u001b[0m in \u001b[0;36mget_notes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# chord (a list of integers) to the list of notes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalOrder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/notes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/notes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-CKzyazLI1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}